{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOpVwUzCKUxvEuxGTxRVo04"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "s_LNYZcCJP0a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##reusing the multiheadattention class\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_in,d_out,context_length,dropout,num_heads,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.w_query = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.w_key = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.w_value = nn.Linear(d_in,d_out,qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out,d_out) # Corrected d_in to d_out\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length,context_length),diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    b,num_tokens,d_in = x.shape\n",
        "    keys = self.w_key(x)\n",
        "    values = self.w_value(x)\n",
        "    queries = self.w_query(x)\n",
        "    ##splitting matrix by adding a num_heads and head_dim dimensions\n",
        "    keys= keys.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    values = values.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "    queries = queries.view(b,num_tokens,self.num_heads,self.head_dim)\n",
        "\n",
        "    #tranpsoing from shape (b,num_tokens,num_heads,head_dim) to (b,num_heads,num_tokens,head_dim)\n",
        "    keys = keys.transpose(1,2)\n",
        "    values = values.transpose(1,2)\n",
        "    queries = queries.transpose(1,2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2,3) # Fixed typo tranpose -> transpose\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens].unsqueeze(0).unsqueeze(0) # Added unsqueeze for broadcasting\n",
        "\n",
        "    attn_scores.masked_fill_(mask_bool,-torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores /keys.shape[-1]**0.5,dim=-1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec_per_head = (attn_weights @ values).transpose(1,2) # Fixed typo tranpose -> transpose and renamed variable\n",
        "\n",
        "    context_vec = context_vec_per_head.contiguous().view( # Used corrected variable name\n",
        "        b,num_tokens,self.d_out\n",
        "    )\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec\n",
        ""
      ],
      "metadata": {
        "id": "GKpBetmZJ7VL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## layernorm class\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean = x.mean(dim=-1,keepdim=True)\n",
        "    var = x.var(dim=-1,keepdim=True)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift\n",
        ""
      ],
      "metadata": {
        "id": "nA-cSnb5KzzA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi)) * (x + 0.044715 * torch.pow(x,3))\n",
        "    ))\n",
        ""
      ],
      "metadata": {
        "id": "SPKQ07wOKuV8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n",
        ""
      ],
      "metadata": {
        "id": "CD-DdgYIKqdz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out = cfg[\"emb_dim\"],\n",
        "        context_length = cfg[\"context_size\"],\n",
        "        num_heads = cfg[\"n_heads\"],\n",
        "        dropout = cfg[\"drop_rate\"],\n",
        "        qkv_bias = cfg[\"qkv_bias\"]\n",
        "\n",
        "    )\n",
        "    self.ffn = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x) # Fixed typo: dropout_shortcut -> drop_shortcut\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ffn(x) # Fixed typo: ff -> ffn\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x"
      ],
      "metadata": {
        "id": "7i1J0EuMKhPd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_size\"],cfg[\"emb_dim\"]) # Changed context_length to context_size\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "\n",
        "    )\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"],bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self,in_idx):\n",
        "    batch_size,seq_len = in_idx.shape\n",
        "    tok_embeds= self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "        torch.arange(seq_len,device=in_idx.device)\n",
        "    )\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x) # Corrected dropout application\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "dWG0sqSRKa8U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from IPython.utils.process import get_output_error_code\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\":50257,\n",
        "    \"context_size\":256,\n",
        "    \"emb_dim\":768,\n",
        "    \"n_heads\":12,\n",
        "    \"n_layers\":12,\n",
        "    \"drop_rate\":0.1,\n",
        "    \"qkv_bias\":False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgvm52_9LEJP",
        "outputId": "57fdb12c-2d98-45cc-91e7-7d6ab0ef6c43"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (w_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (w_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Here we have made some few adjustment to the `GPT_CONFIG_124M` dictionary by reducing the context size to 256 tokens.\n",
        "* This modification reduces the computatioal demands of training the model, making it possible to carry out the training on a standard laptop cmputer"
      ],
      "metadata": {
        "id": "uAUGgOdEMNKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,idx,max_new_tokens,context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    # Crop idx to the last context_size tokens if it's longer\n",
        "    idx_cond = idx[:,  -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:,-1,:]\n",
        "    probs = torch.softmax(logits,dim=-1)\n",
        "    idx_next = torch.argmax(probs,dim=-1,keepdim=True)\n",
        "    idx = torch.cat((idx,idx_next),dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "jN9zmSnnM6W2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##implementing text generation process\n",
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)# unsqueeze adds the batch dimension\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0) #remove batch dimension\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context,tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_size\"]\n",
        ")\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ssZhjQpMrqr",
        "outputId": "a70d6f0e-4981-4182-f05f-d56865e1d811"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see the model isn't yet producing coherent text because it hasn't undergone training.\n",
        "* To define what makes text 'coherent' or 'high quality' we have to implement a numerical method to evaluate the generated content."
      ],
      "metadata": {
        "id": "WpRLhsHdPJIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2  Calculating the text generation loss."
      ],
      "metadata": {
        "id": "TaXOGNRPPi6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Consider these two input examples, which have already been mapped to token IDs."
      ],
      "metadata": {
        "id": "y7Y9EBmgP0DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "    [\n",
        "        [16833,3626,6100], #every effort moves\n",
        "        [40,1107,588] # I really like\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "9AMmGbJLP8GB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Matching these inpts, the targets contain token IDs we want the model to produce."
      ],
      "metadata": {
        "id": "KFLXkgWXQPR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets = torch.tensor([\n",
        "    [3626,6100,345],#every effort moves you\n",
        "    [1107,588,11311]#really like chocolate\n",
        "])"
      ],
      "metadata": {
        "id": "Yf15rIQpQYJL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Note that these targets are inputs but shifted one position forward. This shifting strategy is crucial for teaching the model to predict the next token in a sequence.\n",
        "* Next we feedthe inputs into the model to calculate logits vectors for the two input examples. The we apply the `softmax` function to transform these logits into probability scores."
      ],
      "metadata": {
        "id": "ZPhXu7hmQs3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "probs = torch.softmax(logits,dim=-1)\n",
        "print(probs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0E6KUARRPo-",
        "outputId": "45091fd7-6e18-4655-f7d7-57f4dbd30ece"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##applying the argmax function to the probability scores to obtain the correspoding token IDs\n",
        "token_ids = torch.argmax(probs,dim=-1,keepdim=True)\n",
        "print(\"Token IDs:\\n\",token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTRqCRH3Rm9r",
        "outputId": "8adece85-ec85-44eb-f648-ad3083f475cc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Given that we have two input batches, each containing three tokens, applying `argmax` function to the probability scores yields two set of outputs, each with three predicted token Ids"
      ],
      "metadata": {
        "id": "0ZqVYEUTSKia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##converting the token IDs back into text\n",
        "print(f\"Target batch1:{token_ids_to_text(targets[0],tokenizer)}\")\n",
        "print(f\"Outputs batch1:\"f\"{token_ids_to_text(token_ids[0].flatten(),tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Dmi7TGSqif",
        "outputId": "0a74b6ab-39ba-4187-e9bf-16d8b50958e3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target batch1: effort moves you\n",
            "Outputs batch1: Armed heNetflix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we can see the model produces random text that is different from the target text because it has not been trained yet.\n",
        "* Model training aims to increase the softmax probability in the index postions corresponding to the correct target token Ids.\n",
        "* This softmax probability is also used in evaluation metric we will implement next to numerically access the model's generated outputs: higher probability in the correct positions, the better."
      ],
      "metadata": {
        "id": "7E1cE0-BTpE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probs1 = probs[text_idx,[0,1,2],targets[text_idx]]\n",
        "print(\"Text 1:\",target_probs1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probs2 = probs[text_idx,[0,1,2],targets[text_idx]]\n",
        "print(\"Text 2: \",target_probs2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdepar6rUspY",
        "outputId": "8d9484d8-efee-49f7-faf8-75be87a6cb6d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4514e-05, 3.1054e-05, 1.1567e-05])\n",
            "Text 2:  tensor([1.0343e-05, 5.6737e-05, 4.7620e-06])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The goal of training an LLM is to maximize relative likelihood of the current token, which involves increasing its probability relative to other tokens.\n",
        "* This way, we ensure the LLM consistently picks the target token i.e the next word in the sentence as the next tokem it generates."
      ],
      "metadata": {
        "id": "ffUd2NVEVudy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##calculating probability scores of the two example batches\n",
        "log_probs =torch.log(torch.cat((target_probs1,target_probs2)))\n",
        "print(log_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmsYrII2YexF",
        "outputId": "452d3c23-4995-4b1b-892e-2a1e429d377b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5045, -10.3798, -11.3674, -11.4792,  -9.7771, -12.2549])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Working with logarithms of the probabilities scores is more managable in mathematical optimization than handling the scores directly."
      ],
      "metadata": {
        "id": "KnEVgEgVY31j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##combining the log probabilities into  single score by computing the averagr\n",
        "avg_log_probs = torch.mean(log_probs)\n",
        "print(avg_log_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYXLEG1ZZLsu",
        "outputId": "3ddda051-9f6b-4d48-9dd1-75512312286b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.7938)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The goal is to get the average log probability as close to 0 as possilbe by updating the model's weights as part of the training process.\n",
        "* However, in deep learning, the common practice isn't to push the average log probability up to 0 but rather to bring the negative average log probability to 0.\n",
        "* The negative average log probability is simply the average log probability multiplied by -1 ."
      ],
      "metadata": {
        "id": "LU5NL63JZhd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probs = avg_log_probs *-1\n",
        "print(neg_avg_log_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2Niy_Voawj-",
        "outputId": "bbfa0d0b-d810-4855-bc70-553edf3dc02e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7938)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recalling shape of the logits and target tensors\n",
        "print(\"Logits shape: \",logits.shape) #dim=batch_size,num_tokens,vocab_size\n",
        "print(\"Target shape: \",targets.shape)#batch_size and num_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMgt3mJpa9xT",
        "outputId": "26203d2f-b5dc-4dc0-ab0e-89f038bcd82e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape:  torch.Size([2, 3, 50257])\n",
            "Target shape:  torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##flattening tensors by combining them over the batch dimension\n",
        "logits_flat = logits.flatten(0,1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits: \",logits_flat.shape)\n",
        "print(\"Flattened targets: \",targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buwOolK_bsAw",
        "outputId": "802f2d73-5521-4833-a31a-c350b2fd6bcc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits:  torch.Size([6, 50257])\n",
            "Flattened targets:  torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Previously, we applied the softmax function, selected the probability scores corresponding to the target IDs, and computed the negative average log probabilites.\n",
        "* Pytorch's `cross_entropy` function will take care of the these steps."
      ],
      "metadata": {
        "id": "O7qGZkEBcvxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss= torch.nn.functional.cross_entropy(logits_flat,targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfSAl1LAcP2t",
        "outputId": "b8d32021-ba2a-417b-d9dc-72d4c6c9729a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7938)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The above resulting loss is the same that we obtained previously when applying the individual steps manually."
      ],
      "metadata": {
        "id": "VOhXHcoXclcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Calculating the trainig and validation set losses."
      ],
      "metadata": {
        "id": "wlgoSnbLdUzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We must first prepare the training and validation datasets that we will use to train the LLM.\n",
        "* To compute loss, we use a very samll text dataset, the \"Notes from the underground\""
      ],
      "metadata": {
        "id": "Yy1fJzqfdcwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = \"https://www.gutenberg.org/cache/epub/600/pg600.txt\"\n",
        "input_file =\"pg600.txt\"\n",
        "urllib.request.urlretrieve(url, input_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9WpObyteHVP",
        "outputId": "9b9f31e4-62f0-4fa9-ffc4-2adc8dff3f65"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pg600.txt', <http.client.HTTPMessage at 0x79b3221455b0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(input_file,'r',encoding='utf-8') as f:\n",
        "  text_data = f.read()"
      ],
      "metadata": {
        "id": "iAmVAuYueetU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters: \",total_characters)\n",
        "print(\"Tokens:\",total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-mdOEm5epz3",
        "outputId": "483d99a6-f456-4c2a-cf67-d3785234ae74"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters:  259118\n",
            "Tokens: 67308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##diving data into training and validation set\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio*len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "9DFMXu2FfQsP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Using the `train_data` and `val_data` subsets, we can now create the respective dataloader reusing the `create_dataloader_v1` function"
      ],
      "metadata": {
        "id": "buXyzObpfwwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a dataset for batched inputs and targets\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)##tokenizes text\n",
        "\n",
        "    for i in range(0,len(token_ids) - max_length,stride):#using sliding window to chuk the book into overlapping sequences of max_length\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "TNuw7nwLiYcD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating a dataloader to generate batches with input-with pairs\n",
        "def create_dataloader_v1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "kHZLJ1aif_xd"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_size\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_size\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_size\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_size\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "Oc14ZANae1NO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader\")\n",
        "for x,y in train_loader:\n",
        "  print(x.shape,y.shape)\n",
        "print(\"\\nValidation loader:\")\n",
        "for x,y in val_loader:\n",
        "  print(x.shape,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ljeRL2kihoP",
        "outputId": "8f5239fc-8d3e-4f8b-df58-93fc3d386600"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##implementing a utility function to calculate the cross entropy loss\n",
        "## of a given batch returned via the training and validation loader\n",
        "def calc_loss_batch(input_batch,target_batch,model,device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(\n",
        "      logits.flatten(0,1),target_batch.flatten()\n",
        "  )\n",
        "  return loss"
      ],
      "metadata": {
        "id": "5WhNMjN0i7sw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##implementing a function to compute the training and validation loss\n",
        "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
        "  total_loss = 0\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "\n",
        "  # Determine the actual number of batches to process\n",
        "  if num_batches is None:\n",
        "    actual_num_batches = len(data_loader)\n",
        "  else:\n",
        "    actual_num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i < actual_num_batches:\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  # Avoid division by zero if actual_num_batches is 0\n",
        "  if actual_num_batches == 0:\n",
        "    return float(\"nan\")\n",
        "  return total_loss / actual_num_batches ##averaging loss over all batches\n"
      ],
      "metadata": {
        "id": "ZDgKO6aWjqr-"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader,model,device)\n",
        "  val_loss = calc_loss_loader(val_loader,model,device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\",val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w04IVeiomF2X",
        "outputId": "fe623a39-09d2-46f7-cdac-dd68300fa844"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.979752308180352\n",
            "Validation loss: 10.972686608632406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The loss values are relatively high because the model has not yet been trainied."
      ],
      "metadata": {
        "id": "D9KQp8INnrSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Training the LLM to generate human like text\n"
      ],
      "metadata": {
        "id": "QIh4sbQmn5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## main function for pretraining LLMs\n",
        "def train_model(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
        "  train_losses,val_losses,track_tokens_seen = [], [], []\n",
        "  tokens_seen,global_step = 0, -1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch,target_batch in train_loader:\n",
        "      optimizer.zero_grad() #rest loss gradients from previous batch iterations\n",
        "      loss = calc_loss_batch(\n",
        "          input_batch,target_batch,model,device\n",
        "      )\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss,val_loss = evaluate_model(\n",
        "            model,train_loader,val_loader,device,eval_iter\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(\n",
        "            f\"Ep {epoch+1} (Step {global_step:06d}):\"\n",
        "            f\"Train Loss {train_loss:.3f},\"\n",
        "            f\"Val loss {val_loss:.2f}\"\n",
        "        )\n",
        "    generate_sample(\n",
        "       model,tokenizer,device,start_context\n",
        "   )\n",
        "    return train_losses,val_losses,track_tokens_seen"
      ],
      "metadata": {
        "id": "mpxhSebboG-U"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,train_loader,val_loader,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_header(\n",
        "        train_loader,model,device,num_batches=eval_iter\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "        val_loader,model,device,num_batces=eval_iter\n",
        "    )\n",
        "  model.train()\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "6pCPHeTeq_Ju"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model,tokenizer,device,start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text(\n",
        "        model=model,\n",
        "        idx=encoded,\n",
        "        max_new_tokens=50,\n",
        "        context_size=context_size\n",
        "    )\n",
        "  decoded_text =token_ids_to_text(tokens_ids,tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\",\" \"))\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "iPZ_nSYcrEjk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}